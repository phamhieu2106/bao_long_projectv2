input {
  jdbc {
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://host.docker.internal:5432/db_baolong"
    jdbc_driver_library => "/usr/share/logstash/postgresql-jdbc.jar"
    jdbc_user => "postgres"
    jdbc_password => "Phieu2106"
    jdbc_paging_enabled => true
    use_column_value => true
    tracking_column => "created_at"
    schedule => "*/10 * * * * *"
    statement => "SELECT id, created_at, customer_code, customer_name, email, phone_number, status_customer FROM public.customer_entity"
  }
}

filter {
  mutate {
    copy => { "id" => "[@metadata][_id]" }
    remove_field => ["@version", "@timestamp"]
    rename => {
        "created_at" => "createdAt"
        "customer_code" => "customerCode"
        "customer_name" => "customerName"
        "phone_number" => "phoneNumber"
        "status_customer" => "statusCustomer"
#        "in_charge_by" => "inChargeBy"
    }
  }

  mutate {
    add_field => {
        "customerNameKeyword" => "%{customerName}"
        "customerNameNoSpecialCharacter" => "%{customerName}"
    }
  }

   ruby {
      code => "
        require 'java'
        java_import java.text.Normalizer

        def remove_diacritics(input)
          normalized_string = Normalizer.normalize(input, Normalizer::Form::NFD)
          pattern = java.util.regex.Pattern.compile('\\p{InCombiningDiacriticalMarks}+')
          matcher = pattern.matcher(normalized_string)
          matcher.replaceAll('').downcase
        end

        event.set('customerNameNoSpecialCharacter', remove_diacritics(event.get('customerName')))
      "
    }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "customers"
    document_id => "%{[@metadata][_id]}"
    manage_template => true
    template => "/usr/share/customer-template.json"
    template_overwrite => true
  }
}

